{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12fb6487-1764-4435-9b3e-f321bda6ab7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Distributed Training for PyTorch Models with Ray on Anyscale\n",
    "The purpose of this notebook is to demonstrate how developpers can implement distributed training methods on PyTorch models at scale with the open-source framework Ray (running on Anyscale platform).\n",
    "The primary focus will be utilizing the Ray Train API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287a7d00-5483-45d4-a4aa-925174342cc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "![piyc](https://images.ctfassets.net/xjan103pcp94/QGnrgOJx9rGd8EfSnVehx/e8080f8a43268238ff3557fdbbbadb4a/RayStack.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913d2f3f-b842-4431-bdbd-f7d90dc036cd",
   "metadata": {},
   "source": [
    "# Steps for this Notebook\n",
    "##### 1. Prepare Dataset\n",
    "##### 2. Model Build\n",
    "##### 3. Distributed Training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b3a645-8f76-4805-83a3-737793a46cd0",
   "metadata": {},
   "source": [
    "# 01 - Prepare Dataset\n",
    "We'll be training a simple image classifer on the classic MNIST dataset. The [MNIST dataset](https://production-media.paperswithcode.com/datasets/MNIST-0000000001-2e09631a_09liOmx.jpg) is a source of handwritten digit images consisting of 60000 training samples and 10000 test samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea898556-eded-4d35-af73-532f225053da",
   "metadata": {},
   "source": [
    "![MNIST](https://production-media.paperswithcode.com/datasets/MNIST-0000000001-2e09631a_09liOmx.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5af92d6d-7f38-4032-b5ff-595ed43271d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "622ecbdd-4bc1-4096-987f-5e618c61f3a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(batch_size):\n",
    "    \"\"\"generates train and test DataLoaders for model training and evaluation\"\"\"\n",
    "    # define required tranformations for images\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.38081))\n",
    "    ])\n",
    "    # download dataset\n",
    "    train_data = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "    test_data = datasets.MNIST('../data', train=False, transform=transform)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=1000, shuffle=True)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b6c624-4a7f-4e2c-9c74-390435198532",
   "metadata": {},
   "source": [
    "# 02 - Model Build\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b81ddd90-7a6c-47d2-b59a-13017329620f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2f6f056-f44e-41f4-a7d8-1ac329d1846a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DigitClassifier(nn.Module):\n",
    "    \"\"\"simple classifier model with convolutions\"\"\"\n",
    "    def __init__(self):\n",
    "        super(DigitClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415ec104-6642-470a-8ed0-4b244eacf7eb",
   "metadata": {},
   "source": [
    "# 03 - Model Training with Ray Train\n",
    "[Ray Train](https://docs.ray.io/en/latest/train/train.html) supports all the most popular frameworks for building machine learning models, falling under the following groups. Trainers are meant for ML practitioners to execute training workloads at scale.\n",
    "* Deep Learning Trainers (PyTorch, TensorFLow, JAX, Horovod)\n",
    "* Tree Based Trainers (XGBoost, LightGBM)\n",
    "* General/Other (Scikit-Learn, HuggingFace)\n",
    "\n",
    "Trainers run training loops on multiple [Ray Actors](https://docs.ray.io/en/latest/ray-core/actors.html#actor-guide) (workers).\n",
    "\n",
    "We will be executing a distributed training job with Ray Train. Since were training a PyTorch based model we'll utilize the [TorchTrainer](https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.TorchTrainer.html) which essentially runs Distributed Data Parallel (DDP) or Fully-Sharded Data Parallel (FSDP) under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cd47f9-0378-4471-99ca-98193a155e5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "![TT](https://docs.ray.io/en/latest/_images/train.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e382e54-e96e-47a7-9f68-693e05cb1b66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import ray\n",
    "from ray import train\n",
    "from ray.air import session, Checkpoint, RunConfig\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.air.config import ScalingConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ace06fb-d69b-4d02-8fbd-e7507881cfa0",
   "metadata": {},
   "source": [
    "### Steps for Running Distributed Training with Ray\n",
    "1. Define train, evaluation, and job execution functions\n",
    "2. Wrap the following training components with the appropriate method for enabling distributed execution\n",
    "    * **Device** ([``ray.train.torch.get_device``](https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.get_device.html)): assigns the correct GPU for each process\n",
    "    * **DataLoader** ([``ray.train.torch.prepare_data_loader``](https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.prepare_data_loader.html)): moves tensors from CPU to GPU and adds [DistributedSampler](https://pytorch.org/docs/stable/data.html?highlight=distributedsampler#torch.utils.data.distributed.DistributedSampler) to the DataLoaders\n",
    "    * **Model** ([``ray.train.torch.prepare_model``](https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.prepare_model.html)): runs DDP/FSDP under the hood\n",
    "3. Set required configurations for running training job:\n",
    "    * **RunConfig** ([``ray.air.RunConfig``](https://docs.ray.io/en/latest/ray-air/api/doc/ray.air.RunConfig.html#ray.air.RunConfig)): defines specs for running a given experiment such as:\n",
    "        * experiment name\n",
    "        * output storage path\n",
    "        * stopping conditions\n",
    "        * checkpoint configurations\n",
    "        * logging\n",
    "    * **ScalingConfig** ([``ray.air.config.ScalingConfig``](https://docs.ray.io/en/latest/ray-air/api/doc/ray.air.ScalingConfig.html#ray.air.ScalingConfig)): allows developpers to specify scaling configurations such as:\n",
    "        * number of workers\n",
    "        * use GPU or not\n",
    "        * max CPU usage per node\n",
    "        * scheduling of workers\n",
    "    * **TorchConfig** ([``ray.train.torch.TorchConfig``](https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.TorchConfig.html#ray-train-torch-torchconfig)): configurations for torch process group:\n",
    "        * backend ([PyTorch backends](https://pytorch.org/docs/stable/distributed.html))\n",
    "        * timeout (seconds)\n",
    "4. Initialize TorchTrainer and run training job\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de26b91-3a01-422a-992b-8ed4ec991c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_job(config):\n",
    "    \"\"\"\n",
    "    function for executing distributing training job\n",
    "    \"\"\"\n",
    "    # prepare train, test sets for distributed execution\n",
    "    train_loader, test_loader = get_dataloaders(batch_size_per_worker)\n",
    "    train_loader = train.torch.prepare_data_loader(\n",
    "        data_loader=train_loader, \n",
    "        add_dist_sampler=True, \n",
    "        move_to_device=True, \n",
    "        auto_transfer=True\n",
    "    )\n",
    "    test_loader = train.torch.prepare_data_loader(\n",
    "        data_loader=test_loader, \n",
    "        add_dist_sampler=True, \n",
    "        move_to_device=True, \n",
    "        auto_transfer=True\n",
    "    )\n",
    "    # wrap model to prepare for distributed training\n",
    "    model = DigitClassifier()\n",
    "    model = train.torch.prepare_model(\n",
    "        model=model,\n",
    "        move_to_device=train.torch.get_device(),\n",
    "        parallel_strategy=config['parallel_strategy'],    \n",
    "    )\n",
    "    # initialize optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=config['learning_rate'])\n",
    "    # track training time elapsed\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    # begin training iterations\n",
    "    for epoch in range(1, config['epochs'] + 1):\n",
    "        train_model(model, train_loader, optimizer, epoch)\n",
    "        evaluate_model(model, test_loader)\n",
    "    end.record()\n",
    "    print(f'Training Time Elapsed: {start.elapsed_time(end) / 1000}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f887e9a3-5980-45b0-af6c-e74ee0025844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, epoch):\n",
    "    \"\"\"executes training iteration for a given epoch\"\"\"\n",
    "    model.train()\n",
    "    ddp_loss = torch.zeros(2).to()\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # generate predictions for the given batch\n",
    "        preds = model(x)\n",
    "        # compute the loss with respect to the target variable\n",
    "        loss = F.nll_loss(preds, y, reduction='sum')\n",
    "        loss.backward()\n",
    "        # update model parameters\n",
    "        optimizer.step()\n",
    "        ddp_loss[0] += loss.item()\n",
    "        ddp_loss[1] += len(x)\n",
    "    # print and record metrics\n",
    "    print(f'Epoch: {epoch} \\tTrain Loss: {ddp_loss[0] / ddp_loss[1]}')\n",
    "    session.report(\n",
    "        metrics={'epoch': epoch, 'train_loss': ddp_loss[0].tolist() / ddp_loss[1].tolist()}, \n",
    "        checkpoint=train.torch.TorchCheckpoint.from_state_dict(model.state_dict())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3271bf21-f950-4ad7-8431-8ab068bd3123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"runs model evaluation with test set, records loss\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    ddp_loss = torch.zeros(3).to()\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            # generate predictions for the given batch\n",
    "            preds = model(x)\n",
    "            # sum the batch losses\n",
    "            ddp_loss[0] += F.nll_loss(preds, y, reduction='sum').item()\n",
    "            # get index of max log-prob\n",
    "            pred = preds.argmax(dim=1, keepdim=True)\n",
    "            ddp_loss[1] += pred.eq(y.view_as(pred)).sum().item()\n",
    "            ddp_loss[2] += len(x)\n",
    "\n",
    "    # print and record metrics\n",
    "    print(f'Test Loss: {ddp_loss[0] / ddp_loss[1]}')\n",
    "    session.report(\n",
    "        metrics={'loss': ddp_loss[0].tolist() / ddp_loss[1].tolist()}, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fea2380c-735c-4eb8-8a49-9fd2c82d8ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set configuration parameters\n",
    "EXPERIMENT_NAME = \"distributed-training-test\"\n",
    "NUM_WORKERS = 2 # number of GPU's\n",
    "MAX_CPU_ALLOCATION = 0.7 # max fraction of CPU used before spinning up another node\n",
    "TIMEOUT = 1800\n",
    "if torch.cuda.is_available():\n",
    "    BACKEND = 'NCCL'\n",
    "else:\n",
    "    BACKEND = 'GLOO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdce13fe-c380-4578-999d-8bf43752d454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup required configurations for running TorchTrainer\n",
    "scaling_config = ScalingConfig(\n",
    "    num_workers=NUM_WORKERS, # number of Ray Actors\n",
    "    use_gpu=True, # utilizes GPU during session\n",
    "    _max_cpu_fraction_per_node=MAX_CPU_ALLOCATION # max fraction of CPU's per node for scheduling Actors   \n",
    ")\n",
    "run_config = RunConfig(\n",
    "    name=EXPERIMENT_NAME,\n",
    ")\n",
    "torch_config = train.torch.TorchConfig(\n",
    "    backend=BACKEND,\n",
    "    timeout_s=TIMEOUT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d84bd54f-8660-4e15-8b83-3c28fe8a1f56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-08-24 10:51:20</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:44.13        </td></tr>\n",
       "<tr><td>Memory:      </td><td>10.5/62.1 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0/32 CPUs, 0/2 GPUs (0.0/2.0 accelerator_type:A10G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_974a6_00000</td><td>TERMINATED</td><td>10.0.11.100:314619</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         24.4592</td><td style=\"text-align: right;\">0.103125</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h24m9s)\u001b[0m Adding 1 node(s) of type worker-node-type-0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 10:50:46,584\tWARNING insufficient_resources_manager.py:128 -- Ignore this message if the cluster is autoscaling. You asked for 1.0 cpu and 2.0 gpu per trial, but the cluster only has 16.0 cpu and 1.0 gpu. Stop the tuning job and adjust the resources requested per trial (possibly via `resources_per_trial` or via `num_workers` for rllib) and/or add more resources to your Ray runtime.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h25m15s)\u001b[0m Resized to 32 CPUs, 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=314705)\u001b[0m 2023-08-24 10:50:56,200\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=2]\n",
      "100%|██████████| 4542/4542 [00:00<00:00, 68774472.09it/s]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "100%|██████████| 1648877/1648877 [00:00<00:00, 32787303.00it/s]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2663, ip=10.0.46.94)\u001b[0m 2023-08-24 10:50:56,200\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=2]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2663, ip=10.0.46.94)\u001b[0m 2023-08-24 10:50:56,200\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=2]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2663, ip=10.0.46.94)\u001b[0m 2023-08-24 10:50:56,200\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2663, ip=10.0.46.94)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2605, ip=10.0.10.120)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=314705)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=314705)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2605, ip=10.0.10.120)\u001b[0m Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=314705)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=314705)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=314705)\u001b[0m 2023-08-24 10:50:58,236\tINFO train_loop_utils.py:286 -- Moving model to device: cuda:0\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=314705)\u001b[0m 2023-08-24 10:50:58,237\tINFO train_loop_utils.py:346 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=314705)\u001b[0m /tmp/ipykernel_44980/3967966900.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=314705)\u001b[0m Epoch: 1 \tTrain Loss: 0.7651033401489258\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2605, ip=10.0.10.120)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=314705)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=314705)\u001b[0m Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=314705)\u001b[0m \u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  experiment_tag</th><th>hostname      </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">    loss</th><th>node_ip    </th><th style=\"text-align: right;\">   pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_974a6_00000</td><td>2023-08-24_10-51-18</td><td>True  </td><td style=\"text-align: right;\">               0</td><td>ip-10-0-11-100</td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">0.103125</td><td>10.0.11.100</td><td style=\"text-align: right;\">314619</td><td style=\"text-align: right;\">             24.4592</td><td style=\"text-align: right;\">           0.70495</td><td style=\"text-align: right;\">       24.4592</td><td style=\"text-align: right;\"> 1692899478</td><td style=\"text-align: right;\">                   4</td><td>974a6_00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=314705)\u001b[0m Test Loss: 0.15693329274654388\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=314705)\u001b[0m Epoch: 2 \tTrain Loss: 0.3557094931602478\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2605, ip=10.0.10.120)\u001b[0m Epoch: 2 \tTrain Loss: 0.3557094931602478\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2605, ip=10.0.10.120)\u001b[0m Test Loss: 0.1238589659333229\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2605, ip=10.0.10.120)\u001b[0m Training Time Elapsed: 19.07108984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 10:51:20,666\tINFO tune.py:945 -- Total run time: 104.14 seconds (104.13 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.10312475409389528, 'timestamp': 1692899478, 'time_this_iter_s': 0.7049496173858643, 'done': True, 'training_iteration': 4, 'trial_id': '974a6_00000', 'date': '2023-08-24_10-51-18', 'time_total_s': 24.459227800369263, 'pid': 314619, 'hostname': 'ip-10-0-11-100', 'node_ip': '10.0.11.100', 'config': {'train_loop_config': {'batch_size': 32, 'epochs': 2, 'learning_rate': 0.001, 'parallel_strategy': 'ddp'}}, 'time_since_restore': 24.459227800369263, 'iterations_since_restore': 4, 'experiment_tag': '0'}\n",
      "TorchCheckpoint(local_path=/home/ray/ray_results/distributed-training-test/TorchTrainer_974a6_00000_0_2023-08-24_10-50-51/checkpoint_000001)\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h30m41s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h30m46s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h30m51s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h30m56s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h31m1s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h31m6s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h31m11s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h31m16s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h31m21s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h31m26s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h31m31s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h31m36s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h31m42s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h31m47s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h31m52s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h31m57s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h32m2s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h32m7s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h32m11s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +2h32m21s)\u001b[0m Resized to 16 CPUs, 1 GPUs.\n"
     ]
    }
   ],
   "source": [
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_job, \n",
    "    train_loop_config={\n",
    "        'batch_size': 32,\n",
    "        'epochs': 2,\n",
    "        'learning_rate': 0.001,\n",
    "        'parallel_strategy': 'ddp' # DDP/FSDP\n",
    "    },\n",
    "    torch_config=torch_config,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config\n",
    ")\n",
    "results = trainer.fit()\n",
    "print(results.metrics)\n",
    "print(results.checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e44b83-a6e6-46bd-909c-2f85acaade7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate Predictions with TorchPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da6b309e-0048-433e-bd4f-77853bdf9bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.09873404598020276,\n",
       " 'timestamp': 1692891306,\n",
       " 'time_this_iter_s': 1.258814811706543,\n",
       " 'done': True,\n",
       " 'training_iteration': 4,\n",
       " 'trial_id': 'bd0ae_00000',\n",
       " 'date': '2023-08-24_08-35-07',\n",
       " 'time_total_s': 25.0549635887146,\n",
       " 'pid': 4472,\n",
       " 'hostname': 'ip-10-0-21-71',\n",
       " 'node_ip': '10.0.21.71',\n",
       " 'config': {'train_loop_config': {'batch_size': 32,\n",
       "   'epochs': 2,\n",
       "   'learning_rate': 0.001,\n",
       "   'parallel_strategy': 'ddp'}},\n",
       " 'time_since_restore': 25.0549635887146,\n",
       " 'iterations_since_restore': 4,\n",
       " 'experiment_tag': '0'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +34m43s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +34m53s)\u001b[0m Resized to 16 CPUs, 1 GPUs.\n"
     ]
    }
   ],
   "source": [
    "results.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c80e64a-9612-4dbe-bfb5-6fc2ccb708fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +15m8s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +15m13s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +15m19s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +15m24s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +15m29s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +15m34s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +15m39s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +15m44s)\u001b[0m Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +15m54s)\u001b[0m Resized to 16 CPUs, 1 GPUs.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = results.checkpoint.get_model(DigitClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca47adc3-069a-475d-a231-2fe7b3768e93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = train.torch.TorchPredictor(\n",
    "    model=model_checkpoint,\n",
    "    use_gpu=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef802843-8b59-4148-94e6-61eac1e2e975",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 85115374.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 90534898.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 33736384.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 17639378.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = get_dataloaders(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccc0d40-2117-4009-97f4-08bfe75cee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in test_loader:\n",
    "    x, y = x.to(torch.device('cuda')), y.to(torch.device('cuda'))\n",
    "    pred = predictor.predict(x)\n",
    "    print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
